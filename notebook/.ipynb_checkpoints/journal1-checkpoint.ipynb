{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from scipy.stats import wilcoxon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell 2\n",
    "\n",
    "num_patients = 100  # Adjust if needed\n",
    "\n",
    "# Generates treated group\n",
    "treated = pd.DataFrame({\n",
    "    'id': range(num_patients),\n",
    "    'pain_score': np.random.randint(0, 10, num_patients),\n",
    "    'urgency_score': np.random.randint(0, 10, num_patients),\n",
    "    'frequency': np.random.randint(0, 10, num_patients),\n",
    "    'treated': 1\n",
    "})\n",
    "\n",
    "# Generates untreated group\n",
    "untreated = pd.DataFrame({\n",
    "    'id': range(num_patients, 2 * num_patients),\n",
    "    'pain_score': np.random.randint(0, 10, num_patients),\n",
    "    'urgency_score': np.random.randint(0, 10, num_patients),\n",
    "    'frequency': np.random.randint(0, 10, num_patients),\n",
    "    'treated': 0\n",
    "})\n",
    "\n",
    "# Combines both the treated and untreated patients\n",
    "df = pd.concat([treated, untreated], ignore_index=True)\n",
    "\n",
    "# This one like saves it to csv essentially\n",
    "df.to_csv(\"synthetic_data.csv\", index=False)\n",
    "\n",
    "# To be displayed in like the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#cell 3\n",
    "\n",
    "# Load dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"synthetic_data.csv\")\n",
    "    display(df.head())  # Display head only if file is found\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: synthetic_data.csv not found.  Please make sure it's in the same directory as this notebook.\")\n",
    "    # You could also raise an exception here to halt execution if the file is critical:\n",
    "    # raise  # Uncomment if you want to stop execution\n",
    "except Exception as e: # Catch other potential errors, like incorrect file format\n",
    "    print(f\"An error occurred while reading the CSV: {e}\")\n",
    "    # raise # Uncomment if you want to stop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell 4\n",
    "\n",
    "# Split dataset into treated and untreated\n",
    "try:\n",
    "    treated = df[df['treated'] == 1].reset_index(drop=True)\n",
    "    untreated = df[df['treated'] == 0].reset_index(drop=True)\n",
    "except KeyError:\n",
    "    print(\"Error: 'treated' column not found in the DataFrame. Please check the column name.\")\n",
    "\n",
    "# Define covariates for matching\n",
    "covariates = ['pain_score', 'urgency_score', 'frequency']\n",
    "\n",
    "# Check if covariates are in the dataframe\n",
    "for covariate in covariates:\n",
    "    if covariate not in df.columns:\n",
    "        raise KeyError(f\"Covariate '{covariate}' not found in the DataFrame. Please check the column name.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#cell 5\n",
    "\n",
    "# Compute covariance matrix and its inverse\n",
    "try:\n",
    "    cov_matrix = np.cov(df[covariates].T)\n",
    "    inv_cov_matrix = np.linalg.inv(cov_matrix)\n",
    "except np.linalg.LinAlgError:\n",
    "    print(\"Error: Covariance matrix is singular.  Check for multicollinearity or insufficient data.\")\n",
    "    # Handle the error appropriately (e.g., stop execution, remove correlated variables, add regularization)\n",
    "    raise  # Or handle differently, depending on your needs.\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during covariance calculation: {e}\")\n",
    "    raise\n",
    "\n",
    "# Function to compute Mahalanobis distance (no changes needed here)\n",
    "def compute_mahalanobis(row1, row2):\n",
    "    return mahalanobis(row1[covariates], row2[covariates], inv_cov_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell 6\n",
    "\n",
    "before_matching_distances = []\n",
    "for i, t in treated.iterrows():\n",
    "    for j, u in untreated.iterrows():\n",
    "        before_matching_distances.append(compute_mahalanobis(t, u))\n",
    "\n",
    "print(f\"Median Mahalanobis distance before matching: {np.median(before_matching_distances):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell 7\n",
    "\n",
    "# Create distance matrix\n",
    "num_treated = len(treated)\n",
    "num_untreated = len(untreated)\n",
    "distance_matrix = np.zeros((num_treated, num_untreated))\n",
    "\n",
    "for i, t in treated.iterrows():\n",
    "    for j, u in untreated.iterrows():\n",
    "        distance_matrix[i, j] = compute_mahalanobis(t, u)\n",
    "\n",
    "# Solve optimal matching using Hungarian Algorithm\n",
    "row_ind, col_ind = linear_sum_assignment(distance_matrix)\n",
    "\n",
    "# Compute Mahalanobis Distances After Matching\n",
    "after_matching_distances = [distance_matrix[row, col] for row, col in zip(row_ind, col_ind)]\n",
    "\n",
    "print(f\"Median Mahalanobis distance after matching: {np.median(after_matching_distances):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#cell 8\n",
    "\n",
    "# Create matched pairs\n",
    "matched_pairs = [(treated.iloc[i]['id'], untreated.iloc[j]['id']) for i, j in zip(row_ind, col_ind)]\n",
    "\n",
    "# Create a DataFrame of matched data\n",
    "matched_data = pd.DataFrame(matched_pairs, columns=['treated_id', 'untreated_id'])\n",
    "\n",
    "# More robust merging with correct suffixes (Corrected)\n",
    "treated_matched = treated.iloc[row_ind].reset_index(drop=True)  # Select matched treated\n",
    "untreated_matched = untreated.iloc[col_ind].reset_index(drop=True) # Select matched untreated\n",
    "\n",
    "matched_data = pd.concat([treated_matched.add_suffix('_treated'), untreated_matched.add_suffix('_untreated')], axis=1)\n",
    "\n",
    "\n",
    "# Save matched dataset\n",
    "matched_data.to_csv(\"matched_data.csv\", index=False)\n",
    "\n",
    "# Display first few rows\n",
    "display(matched_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell 9\n",
    "\n",
    "print(\"\\nBefore Matching:\")\n",
    "display(df.groupby('treated')[covariates].describe())\n",
    "\n",
    "print(\"\\nAfter Matching:\")\n",
    "\n",
    "# Dynamically generate the list of columns to display\n",
    "matched_covariates = [f\"{cov}_treated\" for cov in covariates] + [f\"{cov}_untreated\" for cov in covariates]\n",
    "\n",
    "# Check if all columns exist before trying to display them\n",
    "if all(col in matched_data.columns for col in matched_covariates):\n",
    "    display(matched_data[matched_covariates].describe())\n",
    "else:\n",
    "    missing_cols = [col for col in matched_covariates if col not in matched_data.columns]\n",
    "    print(f\"Error: The following columns are missing from matched_data: {missing_cols}\")\n",
    "    # Handle this error as needed (e.g., stop execution, check your merge logic)\n",
    "    # raise # Uncomment to stop execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# cell 10\n",
    "\n",
    "# Before Matching\n",
    "plt.figure(figsize=(10, 5))\n",
    "df.boxplot(column=['pain_score'], by='treated') # Or by 'treated'\n",
    "plt.title(\"Pain Score Distribution Before Matching\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Treated (1 = Yes, 0 = No)\")\n",
    "plt.ylabel(\"Pain Score\")\n",
    "plt.show()\n",
    "\n",
    "# After Matching (Improved)\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Dynamic column selection for boxplot\n",
    "pain_score_cols = [f\"{cov}_treated\" for cov in covariates if cov == 'pain_score'] + [f\"{cov}_untreated\" for cov in covariates if cov == 'pain_score']\n",
    "\n",
    "if all(col in matched_data.columns for col in pain_score_cols):\n",
    "    matched_data[pain_score_cols].boxplot()\n",
    "    plt.title(\"Pain Score Distribution After Matching\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.ylabel(\"Pain Score\")\n",
    "    plt.xticks([1, 2], ['Treated', 'Control'])\n",
    "    plt.show()\n",
    "else:\n",
    "    missing_cols = [col for col in pain_score_cols if col not in matched_data.columns]\n",
    "    print(f\"Error: The following columns are missing from matched_data for the boxplot: {missing_cols}\")\n",
    "    # Handle this error as needed (e.g., stop execution, check your merge logic)\n",
    "    # raise # Uncomment to stop execution\n",
    "\n",
    "# You can repeat this pattern for other covariates if you want boxplots for them as well.\n",
    "# Example for 'urgency_score':\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "urgency_score_cols = [f\"{cov}_treated\" for cov in covariates if cov == 'urgency_score'] + [f\"{cov}_untreated\" for cov in covariates if cov == 'urgency_score']\n",
    "\n",
    "if all(col in matched_data.columns for col in urgency_score_cols):\n",
    "    matched_data[urgency_score_cols].boxplot()\n",
    "    plt.title(\"Urgency Score Distribution After Matching\")\n",
    "    plt.suptitle(\"\")\n",
    "    plt.xlabel(\"Group\")\n",
    "    plt.ylabel(\"Urgency Score\")\n",
    "    plt.xticks([1, 2], ['Treated', 'Control'])\n",
    "    plt.show()\n",
    "else:\n",
    "    missing_cols = [col for col in urgency_score_cols if col not in matched_data.columns]\n",
    "    print(f\"Error: The following columns are missing from matched_data for the boxplot: {missing_cols}\")\n",
    "    # Handle this error as needed (e.g., stop execution, check your merge logic)\n",
    "\n",
    "# And so on for 'frequency' if you want that plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 11: Wilcoxon Signed-Rank Test (Improved)\n",
    "\n",
    "# Check if the required columns exist\n",
    "if 'frequency_treated' in matched_data.columns and 'frequency_untreated' in matched_data.columns:\n",
    "    matched_data['frequency_diff'] = matched_data['frequency_treated'] - matched_data['frequency_untreated']\n",
    "    stat, p_value = wilcoxon(matched_data['frequency_diff'])\n",
    "    print(f\"Wilcoxon test statistic: {stat}, p-value: {p_value}\")\n",
    "else:\n",
    "    missing_cols = []\n",
    "    if 'frequency_treated' not in matched_data.columns:\n",
    "        missing_cols.append('frequency_treated')\n",
    "    if 'frequency_untreated' not in matched_data.columns:\n",
    "        missing_cols.append('frequency_untreated')\n",
    "\n",
    "    print(f\"Error: The following columns are missing from matched_data for the Wilcoxon test: {missing_cols}\")\n",
    "    # Handle this error as needed (e.g., stop execution, check your merge logic)\n",
    "    # raise # Uncomment to stop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Cell 12: Sensitivity Analysis (Improved)\n",
    "\n",
    "gamma_values = [1, 1.5, 2, 2.5, 3]\n",
    "\n",
    "if 'frequency_diff' in matched_data.columns:\n",
    "    for gamma in gamma_values:\n",
    "        bound = np.exp(-gamma * matched_data['frequency_diff'].mean())\n",
    "        print(f\"Gamma: {gamma}, Bound: {bound}\")\n",
    "else:\n",
    "    print(\"Error: 'frequency_diff' column not found in matched_data. Cannot perform sensitivity analysis.\")\n",
    "    # Handle this error as needed (e.g., stop execution, check your merge/calculation logic)\n",
    "    # raise # Uncomment to stop execution"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
